{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeCrossIV/AstraDB-Vector-Search-Yelp-Data/blob/main/Vector_Search_Yelp_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1",
      "metadata": {
        "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1"
      },
      "source": [
        "# Getting Started with this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55",
      "metadata": {
        "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55"
      },
      "source": [
        "- Create a new vector search enabled database in Astra. [astra.datastax.com](https://astra.datastax.com)\n",
        "- For the easy path, name the keyspace in that database \"yelp\" (otherwise be prepared to modify the CQL in this notebook)\n",
        "- Create a token with permissions to create tables\n",
        "- Download your secure-connect-bundle zip file.\n",
        "- Download the Yelp dataset\n",
        "- When you open this notebook in Google Colab or your own notebook server, drag-and-drop the secure connect bundle and yelp_academic_dataset_review.json into the File Browser of the notebook\n",
        "- Set up a Hugging Face account and generate a token\n",
        "- Update the Keys & Environment Variables cell in the notebook with information from the token you generated and the name of your secure connect bundle file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e",
      "metadata": {
        "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e57b18c-275c-40bf-8a71-bbb0c94b2a7b",
      "metadata": {
        "scrolled": true,
        "id": "3e57b18c-275c-40bf-8a71-bbb0c94b2a7b"
      },
      "outputs": [],
      "source": [
        "!pip install pandas jupyter-datatables cassandra-driver transformers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48",
      "metadata": {
        "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01da99af-da9b-4f38-b841-d802ff23bf2f",
      "metadata": {
        "id": "01da99af-da9b-4f38-b841-d802ff23bf2f"
      },
      "outputs": [],
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.query import dict_factory\n",
        "from cassandra.query import SimpleStatement\n",
        "from transformers import AutoTokenizer, AutoModel, tokenization_utils\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d",
      "metadata": {
        "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d"
      },
      "source": [
        "# Keys & Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49",
      "metadata": {
        "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49"
      },
      "outputs": [],
      "source": [
        "# keys and tokens here\n",
        "cass_user = '<Astra DB ClientId goes here>'  # clientId\n",
        "cass_pw = '<Astra DB Secret goes here>' # secret\n",
        "scb_path = '/content/secure-connect-cassio-db.zip'\n",
        "token = \"<Hugging Face Token goes here>\" # hugging face token\n",
        "review_data_file = \"yelp_academic_dataset_review-short.json\"\n",
        "model='sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "create_embeddings=False\n",
        "\n",
        "# set keyspace\n",
        "keyspace=\"yelp\"    # Be sure to have created the yelp keyspace in Astra\n",
        "tablename=\"review\" # The yelp.review table will be created below"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the sample Yelp review data JSON"
      ],
      "metadata": {
        "id": "UQK7jeruHq1V"
      },
      "id": "UQK7jeruHq1V"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://raw.githubusercontent.com/GeorgeCrossIV/AstraDB-Vector-Search-Yelp-Data/main/yelp_academic_dataset_review-short.json\""
      ],
      "metadata": {
        "id": "phDVc4A6Hv6Y"
      },
      "id": "phDVc4A6Hv6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a96369f4-d311-44c2-8469-f960a2a8718a",
      "metadata": {
        "id": "a96369f4-d311-44c2-8469-f960a2a8718a"
      },
      "source": [
        "# Select a model to compute embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get embedding from a model and tokenizer\n",
        "def get_embedding(text, model, tokenizer):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    # Get model output\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the embeddings from the last hidden state\n",
        "    # You might also consider using pooled output for sentence-level embeddings\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # Convert the tensor embeddings into a flat list of floats\n",
        "    float_embeddings = embeddings.numpy().flatten().tolist()\n",
        "\n",
        "    return float_embeddings\n",
        "\n",
        "# Load pretrained MiniLM model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, token=token)\n",
        "model = AutoModel.from_pretrained(model, token=token)\n",
        "\n",
        "# Test text\n",
        "#text = \"Create embeddings using MiniLM.\"\n",
        "\n",
        "# Get embedding\n",
        "#embedding = get_embedding(text, model, tokenizer)\n",
        "\n",
        "# Print embedding\n",
        "#print(embedding)"
      ],
      "metadata": {
        "id": "HiORX1qzoXlA"
      },
      "id": "HiORX1qzoXlA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455",
      "metadata": {
        "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455"
      },
      "source": [
        "# Connect to the Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df",
      "metadata": {
        "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df"
      },
      "outputs": [],
      "source": [
        "cloud_config= {\n",
        "  'secure_connect_bundle': scb_path\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(cass_user, cass_pw)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\n",
        "session = cluster.connect()\n",
        "session.set_keyspace('yelp')\n",
        "session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0670b30f-927f-47da-b71d-0a99092c3f58",
      "metadata": {
        "id": "0670b30f-927f-47da-b71d-0a99092c3f58"
      },
      "source": [
        "# Drop / Create Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf0fd4c-8367-4d5f-983f-5aa7d14a8948",
      "metadata": {
        "id": "acf0fd4c-8367-4d5f-983f-5aa7d14a8948"
      },
      "outputs": [],
      "source": [
        "# only use this to reset the schema\n",
        "if create_embeddings:\n",
        "  session.execute(f\"\"\"DROP INDEX IF EXISTS {keyspace}.minilm_desc\"\"\")\n",
        "  session.execute(f\"\"\"DROP TABLE IF EXISTS {keyspace}.{tablename}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a941c487-1c6b-4f46-a0a3-305a95931d82",
      "metadata": {
        "id": "a941c487-1c6b-4f46-a0a3-305a95931d82"
      },
      "outputs": [],
      "source": [
        "# # Create Table\n",
        "if create_embeddings:\n",
        "  session.execute(f\"\"\"\n",
        "    CREATE TABLE {keyspace}.{tablename} (\n",
        "        review_id Text PRIMARY KEY,\n",
        "        user_id Text,\n",
        "        business_id Text,\n",
        "        stars INT,\n",
        "        date TIMESTAMP,\n",
        "        text TEXT,\n",
        "        useful INT,\n",
        "        funny INT,\n",
        "        cool INT,\n",
        "        minilm_description_embedding vector<float, 384>,\n",
        "    )\n",
        "  \"\"\")\n",
        "\n",
        "  # # Create Index\n",
        "  # Valid values for the similarity_function are COSINE (default), DOT_PRODUCT, or EUCLIDEAN\n",
        "  session.execute(f\"\"\"\n",
        "  CREATE CUSTOM INDEX IF NOT EXISTS minilm_desc\n",
        "  ON {keyspace}.{tablename} (minilm_description_embedding) USING 'StorageAttachedIndex'\n",
        "  WITH OPTIONS = {{ 'similarity_function': 'COSINE' }}\n",
        "  \"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1fe256f-9efb-41f0-8803-d99696c6089b",
      "metadata": {
        "id": "c1fe256f-9efb-41f0-8803-d99696c6089b"
      },
      "source": [
        "# Load the table with data and create text embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yelp_review_data(file_path, number_of_rows=0):\n",
        "    \"\"\"\n",
        "    Load Yelp data from a JSON file into a pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path: str, the path to the JSON file.\n",
        "    - number_of_rows: int, optional, the number of rows to load.\n",
        "                      Load all rows if number_of_rows is missing or zero.\n",
        "\n",
        "    Returns:\n",
        "    - df: pandas DataFrame containing the loaded data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if number_of_rows > 0:\n",
        "            # Load a specified number of rows\n",
        "            df = pd.read_json(file_path, lines=True, nrows=number_of_rows)\n",
        "        else:\n",
        "            # Load all rows if number_of_rows is missing or zero\n",
        "            df = pd.read_json(file_path, lines=True)\n",
        "\n",
        "        # Display the loaded DataFrame\n",
        "        #print(df.head())\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at path '{file_path}' does not exist.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the file: {e}\")\n",
        "\n",
        "# Load the data: For testing purposes, only five records are loaded. Change to 0 to load all of the data\n",
        "review_data = load_yelp_review_data(review_data_file, 10)\n",
        "review_data"
      ],
      "metadata": {
        "id": "zOdPYqHazZX1"
      },
      "id": "zOdPYqHazZX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14eb4355-9fcd-4795-8406-aee98fd4b11f",
      "metadata": {
        "scrolled": true,
        "id": "14eb4355-9fcd-4795-8406-aee98fd4b11f"
      },
      "outputs": [],
      "source": [
        "if create_embeddings:\n",
        "  for id, row in review_data.iterrows():\n",
        "    # Create Embedding for each review row, save them to the database\n",
        "    embedding = get_embedding(row.text, model, tokenizer)\n",
        "    query = SimpleStatement(\n",
        "                f\"\"\"\n",
        "                INSERT INTO {keyspace}.{tablename}\n",
        "                (review_id, business_id, cool, funny, minilm_description_embedding, stars, text, useful, user_id)\n",
        "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
        "                \"\"\"\n",
        "            )\n",
        "    #display(row.text)\n",
        "\n",
        "    session.execute(query, (row.review_id, row.business_id, row.cool, row.funny, embedding, row.stars, row.text, row.useful, row.user_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc20311-5fde-46b1-b194-4611866f4264",
      "metadata": {
        "id": "2fc20311-5fde-46b1-b194-4611866f4264"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Start using the index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f833ef-6555-452b-a903-9505c77b75b1",
      "metadata": {
        "id": "83f833ef-6555-452b-a903-9505c77b75b1"
      },
      "source": [
        "In the steps up to this point, we have been creating a schema and loading the table with data, including embeddings we generated through the MiniLM Embedding API."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466ca4e3-7bb6-485b-ac3a-788c1fe3658d",
      "metadata": {
        "id": "466ca4e3-7bb6-485b-ac3a-788c1fe3658d"
      },
      "source": [
        "# Convert a query string into a text embedding to use as part of the query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37217051-b389-49eb-8b5b-6efb14d9f8c4",
      "metadata": {
        "id": "37217051-b389-49eb-8b5b-6efb14d9f8c4"
      },
      "source": [
        "This is where the real fun starts.  Provide a question or request to be used as the query.  The source sample database is mostly consumer electronics and appliances, so imagine you're talking to a customer service rep at Best Buy or another electronics store.\n",
        "\n",
        "Here we use the same API that we used to calculate embeddings for each row in the database, but this time we are using your input question to calculate a vector to use in a query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e891b68c-5e31-4b6f-915f-f05f684529b4",
      "metadata": {
        "scrolled": true,
        "id": "e891b68c-5e31-4b6f-915f-f05f684529b4"
      },
      "outputs": [],
      "source": [
        "customer_input = \"Which review mention cycling?'\"\n",
        "\n",
        "embedding = get_embedding(customer_input, model, tokenizer)\n",
        "#display(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1036a24f-d527-410b-b73c-d2e191b792a5",
      "metadata": {
        "id": "1036a24f-d527-410b-b73c-d2e191b792a5"
      },
      "source": [
        "Let's take a look at what a query against a vector index could look like.  The query vector has the same dimensions (number of entries in the list) as the embeddings we generated a few steps ago for each row in the database."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use the following similarity functions: similarity_dot_product, similarity_cosine, similarity_euclidean\n",
        "\n",
        "documentation - https://docs.datastax.com/en/astra-serverless/docs/vector-search/cql.html#_calculate_the_similarity."
      ],
      "metadata": {
        "id": "jmjbQpGZnVTn"
      },
      "id": "jmjbQpGZnVTn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed786879-c639-458c-84e4-b657b2fba9a1",
      "metadata": {
        "scrolled": true,
        "id": "ed786879-c639-458c-84e4-b657b2fba9a1"
      },
      "outputs": [],
      "source": [
        "query = SimpleStatement(\n",
        "    f\"\"\"\n",
        "    SELECT review_id, stars, text, similarity_cosine(minilm_description_embedding, {embedding}) as similarity\n",
        "    FROM {keyspace}.{tablename}\n",
        "    ORDER BY minilm_description_embedding ANN OF {embedding} LIMIT 5;\n",
        "    \"\"\"\n",
        "    )\n",
        "#display(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93edd66f-4ffc-4133-943e-b0266c704f49",
      "metadata": {
        "id": "93edd66f-4ffc-4133-943e-b0266c704f49"
      },
      "source": [
        "# Find the top 5 results using ANN Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be4acfe-bd54-462c-9f96-acae2228d633",
      "metadata": {
        "id": "6be4acfe-bd54-462c-9f96-acae2228d633"
      },
      "outputs": [],
      "source": [
        "results = session.execute(query)\n",
        "top_reviews = results._current_rows\n",
        "\n",
        "for row in top_reviews:\n",
        "  print(f\"\"\"{row.similarity}, {row.review_id}, {row.stars}, {row.text}\\n\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ask another question: What review mentions poultry?"
      ],
      "metadata": {
        "id": "OFuUdkcARQjr"
      },
      "id": "OFuUdkcARQjr"
    },
    {
      "cell_type": "code",
      "source": [
        "customer_input = \"Which review mention poultry?'\"\n",
        "embedding = get_embedding(customer_input, model, tokenizer)\n",
        "\n",
        "query = SimpleStatement(\n",
        "    f\"\"\"\n",
        "    SELECT review_id, stars, text, similarity_cosine(minilm_description_embedding, {embedding}) as similarity\n",
        "    FROM {keyspace}.{tablename}\n",
        "    ORDER BY minilm_description_embedding ANN OF {embedding} LIMIT 5;\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "results = session.execute(query)\n",
        "top_reviews = results._current_rows\n",
        "\n",
        "for row in top_reviews:\n",
        "  print(f\"\"\"{row.similarity}, {row.review_id}, {row.stars}, {row.text}\\n\"\"\")"
      ],
      "metadata": {
        "id": "0AXtiykzRW4z"
      },
      "id": "0AXtiykzRW4z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}